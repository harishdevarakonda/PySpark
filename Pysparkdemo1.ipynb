{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bf3afc3-8dd5-434a-8d6d-d2c47728f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "from pyspark.sql import SparkSession \n",
    "spark=SparkSession.builder.appName(\"Sample\").getOrCreate()\n",
    "df=spark.read.csv('emp_1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e30124a-2ac2-427f-ad9f-c9a1dd9237be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+-------+----+-----+\n",
      "|   _c0|   _c1|   _c2|    _c3| _c4|  _c5|\n",
      "+------+------+------+-------+----+-----+\n",
      "|emp_id|  name|salary|address| loc|email|\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "+------+------+------+-------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read dataframe\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f866c8f-a1c4-437e-9efd-eaad9d53e2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string, _c5: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e07bbe2-2832-4c94-8f02-a087a397f228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[emp_id: string, name: string, salary: string, address: string, loc: string, email: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1=spark.read.csv('emp_1.csv',header=True)\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f44df2c-e949-4d37-825d-d2d3572d6bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+-------+----+-----+\n",
      "|emp_id|  name|salary|address| loc|email|\n",
      "+------+------+------+-------+----+-----+\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "+------+------+------+-------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ed2b2f4-04c8-40de-8a28-764dc8a49e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- loc: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eabbe473-9e7e-4a0f-a870-967ea13b86c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[emp_id: int, name: string, salary: int, address: string, loc: string, email: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+-------+----+-----+\n",
      "|emp_id|  name|salary|address| loc|email|\n",
      "+------+------+------+-------+----+-----+\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "+------+------+------+-------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataframe with header and proper schema\n",
    "df2=spark.read.csv('emp_1.csv',header=True,inferSchema=True)\n",
    "display(df2)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a85d5697-dd07-4bba-b07c-91861e64efc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- loc: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dde64905-1668-4b2f-a973-83032cc54349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[emp_id: int, name: string, salary: int, address: string, loc: string, email: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+-------+----+-----+\n",
      "|emp_id|  name|salary|address| loc|email|\n",
      "+------+------+------+-------+----+-----+\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "+------+------+------+-------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3=spark.read.format(\"csv\").options(header=True,inferSchema=True).load('emp_1.csv')\n",
    "display(df3)\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b90071de-c0e5-4003-bcc5-420ea7c00aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+-------+----+-----+\n",
      "|emp_id|  name|salary|address| loc|email|\n",
      "+------+------+------+-------+----+-----+\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "+------+------+------+-------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4=spark.read.csv('emp_1.csv',header=True,inferSchema=True)\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "297689f8-6809-4400-9cef-a62d0902b389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|emp_id|salary|\n",
      "+------+------+\n",
      "|     1| 10000|\n",
      "|     2| 20000|\n",
      "|     3| 55000|\n",
      "|     4| 12000|\n",
      "|     5| 20000|\n",
      "|     6|  NULL|\n",
      "|     1| 10000|\n",
      "|     2| 20000|\n",
      "|     3| 55000|\n",
      "|     4| 12000|\n",
      "|     5| 20000|\n",
      "|     6|  NULL|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.select(\"emp_id\",\"salary\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61cfa388-c5ab-4926-b7ba-9fd1daaaacd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|emp_id|salary|\n",
      "+------+------+\n",
      "|     1| 10000|\n",
      "|     2| 20000|\n",
      "|     3| 55000|\n",
      "|     4| 12000|\n",
      "|     5| 20000|\n",
      "|     6|  NULL|\n",
      "|     1| 10000|\n",
      "|     2| 20000|\n",
      "|     3| 55000|\n",
      "|     4| 12000|\n",
      "|     5| 20000|\n",
      "|     6|  NULL|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.select(df4.emp_id,df4.salary).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "416d2737-a047-4db2-808c-651f85595724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|  name|salary|\n",
      "+------+------+\n",
      "|manish| 10000|\n",
      "|  rani| 20000|\n",
      "| rinku| 55000|\n",
      "|  neha| 12000|\n",
      "|  NULL| 20000|\n",
      "| rahul|  NULL|\n",
      "|manish| 10000|\n",
      "|  rani| 20000|\n",
      "| rinku| 55000|\n",
      "|  neha| 12000|\n",
      "|  NULL| 20000|\n",
      "| rahul|  NULL|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.select(df4.columns[1:3]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f7018e2-658a-424a-9cbd-05f6c2f24502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+-------+----+-----+\n",
      "|   _c0|   _c1|   _c2|    _c3| _c4|  _c5|\n",
      "+------+------+------+-------+----+-----+\n",
      "|emp_id|  name|salary|address| loc|email|\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "+------+------+------+-------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdabfa60-e741-44b4-80a9-1ee5f42fbbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+-------+----+-----+--------+\n",
      "|emp_id|  name|salary|address| loc|email| salary1|\n",
      "+------+------+------+-------+----+-----+--------+\n",
      "|     1|manish| 10000|  india|NULL| NULL|100000.0|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|200000.0|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|550000.0|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|120000.0|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|200000.0|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|    NULL|\n",
      "|     1|manish| 10000|  india|NULL| NULL|100000.0|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|200000.0|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|550000.0|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|120000.0|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|200000.0|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|    NULL|\n",
      "+------+------+------+-------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add new column based on existing column \n",
    "df5=spark.read.csv('emp_1.csv',header=True)\n",
    "df5.withColumn(\"salary1\",df5.salary*10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efc5e260-c9b1-4014-9ecb-25037b7c1004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+-------+----+-----+-------+\n",
      "|emp_id|  name|salary|address| loc|email|country|\n",
      "+------+------+------+-------+----+-----+-------+\n",
      "|     1|manish| 10000|  india|NULL| NULL|    usa|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|    usa|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|    usa|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|    usa|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|    usa|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|    usa|\n",
      "|     1|manish| 10000|  india|NULL| NULL|    usa|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|    usa|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|    usa|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|    usa|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|    usa|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|    usa|\n",
      "+------+------+------+-------+----+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add new column based on constant value\n",
    "from pyspark.sql.functions import lit\n",
    "df6=spark.read.csv('emp_1.csv',header=True)\n",
    "df6.withColumn(\"country\",lit(\"usa\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2e99eff-71af-4ce9-9d83-ad2a9a79b937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+-------+----+-----+---------+\n",
      "|emp_id|  name|salary|address| loc|email|increment|\n",
      "+------+------+------+-------+----+-----+---------+\n",
      "|     1|manish| 10000|  india|NULL| NULL|        0|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|        0|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|        0|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|        0|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|        0|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|        0|\n",
      "|     1|manish| 10000|  india|NULL| NULL|        0|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|        0|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|        0|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|        0|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|        0|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|        0|\n",
      "+------+------+------+-------+----+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6.withColumn(\"increment\",lit(0)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b7afd01-6b1c-44cd-8810-2d87730c1786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- loc: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n",
      "+------+------+------+-------+----+-----+\n",
      "|emp_id|  name|salary|address| loc|email|\n",
      "+------+------+------+-------+----+-----+\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "+------+------+------+-------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df7=spark.read.csv('emp_1.csv',header=True)\n",
    "df7.printSchema()\n",
    "df7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70f48b40-0427-467d-880a-52dd173011c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+-------+----+-----+\n",
      "|emp_id|  name|salary|address| loc|email|\n",
      "+------+------+------+-------+----+-----+\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "+------+------+------+-------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df8=df7.withColumn(\"salary\",col(\"salary\").cast(\"Integer\"))\n",
    "df8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6769d577-c8ef-41f7-bcd3-637dd3ec8273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- loc: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df8.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60c7b17b-a6d2-4781-9c95-a0be5acbac1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+-------+--------+-----+\n",
      "|emp_id|  name|salary|address|location|email|\n",
      "+------+------+------+-------+--------+-----+\n",
      "|     1|manish| 10000|  india|    NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|    NULL| NULL|\n",
      "|     3| rinku| 55000|  india|    NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|    NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|    NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|    NULL| NULL|\n",
      "|     1|manish| 10000|  india|    NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|    NULL| NULL|\n",
      "|     3| rinku| 55000|  india|    NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|    NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|    NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|    NULL| NULL|\n",
      "+------+------+------+-------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df8.withColumnRenamed(\"loc\",\"location\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d8b722c-bc3b-4b82-acec-e7121e7c01ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------+-------+----+-----+\n",
      "|emp_id| name|salary|address| loc|email|\n",
      "+------+-----+------+-------+----+-----+\n",
      "|     2| rani| 20000|    usa|NULL| NULL|\n",
      "|     3|rinku| 55000|  india|NULL| NULL|\n",
      "|     6|rahul|  NULL|  india|NULL| NULL|\n",
      "|     2| rani| 20000|    usa|NULL| NULL|\n",
      "|     3|rinku| 55000|  india|NULL| NULL|\n",
      "|     6|rahul|  NULL|  india|NULL| NULL|\n",
      "+------+-----+------+-------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df9=spark.read.csv('emp_1.csv',header=True)\n",
    "df9.filter(df9.name.startswith(\"r\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f541d326-0263-4edb-ad84-5ace61ac7f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+-------+----+-----+\n",
      "|emp_id|  name|salary|address| loc|email|\n",
      "+------+------+------+-------+----+-----+\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "+------+------+------+-------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df10=df9.distinct()\n",
    "df10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89562ac5-d6bd-466f-a63c-a49fc6b3f276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+-------+----+-----+\n",
      "|emp_id|  name|salary|address| loc|email|\n",
      "+------+------+------+-------+----+-----+\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "+------+------+------+-------+----+-----+\n",
      "\n",
      "+------+------+------+-------+----+-----+\n",
      "|emp_id|  name|salary|address| loc|email|\n",
      "+------+------+------+-------+----+-----+\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "+------+------+------+-------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df11=spark.read.csv('emp_1.csv',header=True)\n",
    "df11.show()\n",
    "df12=df11.dropDuplicates(['emp_id','salary'])\n",
    "df12.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "609e8d5f-2a86-4548-9f18-dd218a8031e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+-------+----+-----+\n",
      "|emp_id|  name|salary|address| loc|email|\n",
      "+------+------+------+-------+----+-----+\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "+------+------+------+-------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df11.sort(\"salary\",\"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a55f0f9f-7816-40e0-beeb-6acb86ac5215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+-------+----+-----+\n",
      "|emp_id|  name|salary|address| loc|email|\n",
      "+------+------+------+-------+----+-----+\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "+------+------+------+-------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df11.orderBy(\"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "70311202-8430-46cf-938a-a88226d4ecf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+-------+----+-----+\n",
      "|emp_id|  name|salary|address| loc|email|\n",
      "+------+------+------+-------+----+-----+\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     3| rinku| 55000|  india|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     2|  rani| 20000|    usa|NULL| NULL|\n",
      "|     5|  NULL| 20000|    usa|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     4|  neha| 12000|    usa|NULL| NULL|\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     1|manish| 10000|  india|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "|     6| rahul|  NULL|  india|NULL| NULL|\n",
      "+------+------+------+-------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df14=spark.read.csv('emp_1.csv',header=True)\n",
    "df14.sort(df14.salary.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954d866f-6d64-4194-8395-345e39f6e791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
